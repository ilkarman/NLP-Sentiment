{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Three different ways of running mxnet on classic MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "def download_file(url):\n",
    "    \"\"\"\n",
    "    Downloads a file from a url if the file does not exist in the current folder\n",
    "    :param url: Url to the file\n",
    "    \"\"\"\n",
    "    local_filename = url.split('/')[-1]\n",
    "    if os.path.isfile(local_filename):\n",
    "        print(\"The file %s already exist in the current directory\" % local_filename)\n",
    "    else:\n",
    "        print('downloading data: %s' % url)\n",
    "        response = wget.download(url)\n",
    "        print('saved data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file https://hoaphumanoidstorage2.blob.core.windows.net/public/mnist_train.csv\n",
      "The file mnist_train.csv already exist in the current directory\n",
      "Downloading file https://hoaphumanoidstorage2.blob.core.windows.net/public/mnist_test.csv\n",
      "The file mnist_test.csv already exist in the current directory\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "url_train = 'https://hoaphumanoidstorage2.blob.core.windows.net/public/mnist_train.csv'\n",
    "url_test = 'https://hoaphumanoidstorage2.blob.core.windows.net/public/mnist_test.csv'\n",
    "\n",
    "print(\"Downloading file %s\" % url_train)\n",
    "download_file(url_train)\n",
    "\n",
    "print(\"Downloading file %s\" % url_test)\n",
    "download_file(url_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://yann.lecun.com/exdb/mnist/\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "DATA_SHAPE = (BATCH_SIZE, 1, 28, 28)\n",
    "EPOCHS = 10\n",
    "LR  = 0.1\n",
    "MOM = 0.9\n",
    "WD = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logging\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='lenet.log', mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gather data\n",
    "train = pd.read_csv('mnist_train.csv', header=None)\n",
    "train_y = train[[0]].values.ravel()\n",
    "train_x = train.iloc[:,1:].values\n",
    "\n",
    "# modify data\n",
    "train_x = np.array(train_x, dtype='float32').reshape((-1, 1, 28, 28))\n",
    "#print(train_x.shape)  # (60000, 1, 28, 28)\n",
    "# normalise (between 0 and 1)\n",
    "train_x[:] /= 255.0\n",
    "\n",
    "# iterator to feed mini_batch at a time\n",
    "# returns <mxnet.io.DataBatch object at 0x000001AA996B38D0> \n",
    "# type <class 'mxnet.io.DataBatch'>\n",
    "train_iter = mx.io.NDArrayIter(train_x, train_y, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lenet():\n",
    "    # create symbolic representation\n",
    "    data = mx.symbol.Variable('data')\n",
    "    input_y = mx.sym.Variable('softmax_label')  # placeholder for output\n",
    "\n",
    "    conv1 = mx.symbol.Convolution(\n",
    "        data=data, kernel=(5,5), num_filter=20)\n",
    "    tanh1 = mx.symbol.Activation(\n",
    "        data=conv1, act_type=\"tanh\")\n",
    "    pool1 = mx.symbol.Pooling(\n",
    "        data=tanh1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "\n",
    "    conv2 = mx.symbol.Convolution(\n",
    "        data=pool1, kernel=(5,5), num_filter=50)\n",
    "    tanh2 = mx.symbol.Activation(\n",
    "        data=conv2, act_type=\"tanh\")\n",
    "    pool2 = mx.symbol.Pooling(\n",
    "        data=tanh2, pool_type=\"max\", kernel=(2,2), stride=(2,2)) \n",
    "\n",
    "    flatten = mx.symbol.Flatten(\n",
    "        data=pool2)\n",
    "    \n",
    "    fc1 = mx.symbol.FullyConnected(\n",
    "        data=flatten, num_hidden=500) \n",
    "    tanh3 = mx.symbol.Activation(\n",
    "        data=fc1, act_type=\"tanh\")\n",
    "\n",
    "    fc2 = mx.symbol.FullyConnected(\n",
    "        data=tanh3, num_hidden=10) \n",
    "\n",
    "    lenet = mx.symbol.SoftmaxOutput(\n",
    "        data=fc2, label=input_y, name=\"softmax\")\n",
    "    return lenet\n",
    "\n",
    "# train the NN\n",
    "ctx = mx.cpu()\n",
    "cnn = create_lenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: plot Pages: 1 -->\r\n",
       "<svg width=\"102pt\" height=\"1006pt\"\r\n",
       " viewBox=\"0.00 0.00 102.00 1006.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1002)\">\r\n",
       "<title>plot</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1002 98,-1002 98,4 -4,4\"/>\r\n",
       "<!-- convolution0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>convolution0</title>\r\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"94,-58 -7.10543e-015,-58 -7.10543e-015,-0 94,-0 94,-58\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-32.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-17.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5x5/1, 20</text>\r\n",
       "</g>\r\n",
       "<!-- activation0 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>activation0</title>\r\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"94,-152 -7.10543e-015,-152 -7.10543e-015,-94 94,-94 94,-152\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tanh</text>\r\n",
       "</g>\r\n",
       "<!-- activation0&#45;&gt;convolution0 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>activation0&#45;&gt;convolution0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-83.7443C47,-75.2043 47,-66.2977 47,-58.2479\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-93.8971 42.5001,-83.897 47,-88.8971 47.0001,-83.8971 47.0001,-83.8971 47.0001,-83.8971 47,-88.8971 51.5001,-83.8971 47,-93.8971 47,-93.8971\"/>\r\n",
       "</g>\r\n",
       "<!-- pooling0 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>pooling0</title>\r\n",
       "<polygon fill=\"#80b1d3\" stroke=\"black\" points=\"94,-246 -7.10543e-015,-246 -7.10543e-015,-188 94,-188 94,-246\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-220.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Pooling</text>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-205.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">max, 2x2/2</text>\r\n",
       "</g>\r\n",
       "<!-- pooling0&#45;&gt;activation0 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>pooling0&#45;&gt;activation0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-177.744C47,-169.204 47,-160.298 47,-152.248\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-187.897 42.5001,-177.897 47,-182.897 47.0001,-177.897 47.0001,-177.897 47.0001,-177.897 47,-182.897 51.5001,-177.897 47,-187.897 47,-187.897\"/>\r\n",
       "</g>\r\n",
       "<!-- convolution1 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>convolution1</title>\r\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"94,-340 -7.10543e-015,-340 -7.10543e-015,-282 94,-282 94,-340\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-314.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-299.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5x5/1, 50</text>\r\n",
       "</g>\r\n",
       "<!-- convolution1&#45;&gt;pooling0 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>convolution1&#45;&gt;pooling0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-271.744C47,-263.204 47,-254.298 47,-246.248\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-281.897 42.5001,-271.897 47,-276.897 47.0001,-271.897 47.0001,-271.897 47.0001,-271.897 47,-276.897 51.5001,-271.897 47,-281.897 47,-281.897\"/>\r\n",
       "</g>\r\n",
       "<!-- activation1 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>activation1</title>\r\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"94,-434 -7.10543e-015,-434 -7.10543e-015,-376 94,-376 94,-434\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-408.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-393.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tanh</text>\r\n",
       "</g>\r\n",
       "<!-- activation1&#45;&gt;convolution1 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>activation1&#45;&gt;convolution1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-365.744C47,-357.204 47,-348.298 47,-340.248\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-375.897 42.5001,-365.897 47,-370.897 47.0001,-365.897 47.0001,-365.897 47.0001,-365.897 47,-370.897 51.5001,-365.897 47,-375.897 47,-375.897\"/>\r\n",
       "</g>\r\n",
       "<!-- pooling1 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>pooling1</title>\r\n",
       "<polygon fill=\"#80b1d3\" stroke=\"black\" points=\"94,-528 -7.10543e-015,-528 -7.10543e-015,-470 94,-470 94,-528\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-502.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Pooling</text>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-487.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">max, 2x2/2</text>\r\n",
       "</g>\r\n",
       "<!-- pooling1&#45;&gt;activation1 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>pooling1&#45;&gt;activation1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-459.744C47,-451.204 47,-442.298 47,-434.248\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-469.897 42.5001,-459.897 47,-464.897 47.0001,-459.897 47.0001,-459.897 47.0001,-459.897 47,-464.897 51.5001,-459.897 47,-469.897 47,-469.897\"/>\r\n",
       "</g>\r\n",
       "<!-- flatten0 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>flatten0</title>\r\n",
       "<polygon fill=\"#fdb462\" stroke=\"black\" points=\"94,-622 -7.10543e-015,-622 -7.10543e-015,-564 94,-564 94,-622\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-589.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Flatten</text>\r\n",
       "</g>\r\n",
       "<!-- flatten0&#45;&gt;pooling1 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>flatten0&#45;&gt;pooling1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-553.744C47,-545.204 47,-536.298 47,-528.248\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-563.897 42.5001,-553.897 47,-558.897 47.0001,-553.897 47.0001,-553.897 47.0001,-553.897 47,-558.897 51.5001,-553.897 47,-563.897 47,-563.897\"/>\r\n",
       "</g>\r\n",
       "<!-- fullyconnected0 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>fullyconnected0</title>\r\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"94,-716 -7.10543e-015,-716 -7.10543e-015,-658 94,-658 94,-716\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-690.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-675.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">500</text>\r\n",
       "</g>\r\n",
       "<!-- fullyconnected0&#45;&gt;flatten0 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>fullyconnected0&#45;&gt;flatten0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-647.744C47,-639.204 47,-630.298 47,-622.248\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-657.897 42.5001,-647.897 47,-652.897 47.0001,-647.897 47.0001,-647.897 47.0001,-647.897 47,-652.897 51.5001,-647.897 47,-657.897 47,-657.897\"/>\r\n",
       "</g>\r\n",
       "<!-- activation2 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>activation2</title>\r\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"94,-810 -7.10543e-015,-810 -7.10543e-015,-752 94,-752 94,-810\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-784.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-769.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tanh</text>\r\n",
       "</g>\r\n",
       "<!-- activation2&#45;&gt;fullyconnected0 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>activation2&#45;&gt;fullyconnected0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-741.744C47,-733.204 47,-724.298 47,-716.248\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-751.897 42.5001,-741.897 47,-746.897 47.0001,-741.897 47.0001,-741.897 47.0001,-741.897 47,-746.897 51.5001,-741.897 47,-751.897 47,-751.897\"/>\r\n",
       "</g>\r\n",
       "<!-- fullyconnected1 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>fullyconnected1</title>\r\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"94,-904 -7.10543e-015,-904 -7.10543e-015,-846 94,-846 94,-904\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-878.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-863.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">10</text>\r\n",
       "</g>\r\n",
       "<!-- fullyconnected1&#45;&gt;activation2 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>fullyconnected1&#45;&gt;activation2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-835.744C47,-827.204 47,-818.298 47,-810.248\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-845.897 42.5001,-835.897 47,-840.897 47.0001,-835.897 47.0001,-835.897 47.0001,-835.897 47,-840.897 51.5001,-835.897 47,-845.897 47,-845.897\"/>\r\n",
       "</g>\r\n",
       "<!-- softmax -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>softmax</title>\r\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"94,-998 -7.10543e-015,-998 -7.10543e-015,-940 94,-940 94,-998\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-965.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SoftmaxOutput</text>\r\n",
       "</g>\r\n",
       "<!-- softmax&#45;&gt;fullyconnected1 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>softmax&#45;&gt;fullyconnected1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-929.744C47,-921.204 47,-912.298 47,-904.248\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-939.897 42.5001,-929.897 47,-934.897 47.0001,-929.897 47.0001,-929.897 47.0001,-929.897 47,-934.897 51.5001,-929.897 47,-939.897 47,-939.897\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x205335f0c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualise symbol (for crepe)\n",
    "mx.viz.plot_network(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'convolution0_weight',\n",
       " 'convolution0_bias',\n",
       " 'convolution1_weight',\n",
       " 'convolution1_bias',\n",
       " 'fullyconnected0_weight',\n",
       " 'fullyconnected0_bias',\n",
       " 'fullyconnected1_weight',\n",
       " 'fullyconnected1_bias',\n",
       " 'softmax_label']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.list_arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Method A - Simple\n",
    "\n",
    "This approach creates the model by automatically binding the symbol `cnn` and letting us define parameters such as learning rate, etc. \n",
    "\n",
    "We then train the model using the `model.fit()` function which accepts an mx.io.iterator for the input and we can optionally save the parameters and log every batch/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup model\n",
    "model = mx.model.FeedForward(\n",
    "    ctx = ctx,\n",
    "    symbol = cnn, \n",
    "    num_epoch = EPOCHS,  # number of training rounds\n",
    "    learning_rate = LR,  # learning rate\n",
    "    momentum = MOM,   # momentum for sgd\n",
    "    wd = WD  # weight decay for reg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "# Log accuracy to file every batch\n",
    "# Save parameters at every epoch\n",
    "tic = time.time()\n",
    "\n",
    "model.fit(\n",
    "    X = train_iter,\n",
    "    eval_metric=['accuracy'],\n",
    "    batch_end_callback=mx.callback.Speedometer(BATCH_SIZE),\n",
    "    epoch_end_callback=mx.callback.do_checkpoint(\"lenet_checkp_\") \n",
    ")\n",
    "\n",
    "print(\"Finished training in %.0f seconds\" % (time.time() - tic))\n",
    "# Finished training in 577 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9901\n"
     ]
    }
   ],
   "source": [
    "# prediction of test set\n",
    "test = pd.read_csv('mnist_test.csv', header=None)\n",
    "test_y = test[[0]].values.ravel()\n",
    "test_x = test.iloc[:,1:].values\n",
    "\n",
    "test_x = np.array(test_x, dtype='float32').reshape((-1, 1, 28, 28))\n",
    "test_x[:] /= 255.0\n",
    "\n",
    "test_iter = mx.io.NDArrayIter(test_x, test_y, batch_size=100)\n",
    "\n",
    "# most likely will be last element after sorting\n",
    "pred = np.argsort(model.predict(X = test_iter))[:,-1]\n",
    "\n",
    "# accuracy\n",
    "print(sum(pred==test_y)/len(test_y))\n",
    "# 0.9901\n",
    "\n",
    "# save\n",
    "np.savetxt('predicted_images.csv', np.c_[pred, test_y], delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Method B - Advanced\n",
    "\n",
    "Instead of using `mx.model.FeedForward` along with `model.fit` we can get more control creating it manually. \n",
    "\n",
    "This stage involves manually attaching the created symbol to the executor, linking the data and label, initialising the weights, and then creating the optimiser (loss).\n",
    "\n",
    "This is particularly useful because it allows us to use a manual_iterator (which can apply an on-the-fly transformation to the data). In this example we normalise on the fly - however this can also be used to produce one-hot-vectors which would massively expand the size of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create own iterator (that can optionally apply transform function)\n",
    "def manual_iterator(infile, batch_size=100, shuffle=True):\n",
    "\n",
    "    \"\"\" Accepts 'infile' location to a .csv and then yields numpy arrays\n",
    "    wrapped as NDarrays using mx.nd.array(np.array(data, dtype='float32'))\n",
    "    reshaped for the CNN symbol i.e. .reshape((LENGTH, 1, FEAT, DIM))\"\"\"\n",
    "    \n",
    "    # load in data\n",
    "    df = pd.read_csv(infile, header=None)\n",
    "    \n",
    "    # shuffle\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    train_x, train_y = df.iloc[:,1:].values, df[[0]].values.ravel()\n",
    "\n",
    "    # modify data\n",
    "    train_x = np.array(train_x, dtype='float32').reshape((-1, 1, 28, 28))\n",
    "    \n",
    "    # transformation\n",
    "    train_x[:] /= 255.0    \n",
    "    \n",
    "    # yield mini-batches as NDArray\n",
    "    X_split = np.zeros(DATA_SHAPE, dtype='float32')\n",
    "    for ti, tx in enumerate(train_x):\n",
    "\n",
    "        X_split[ti%batch_size][0] = tx\n",
    "\n",
    "        if (ti + 1) % batch_size == 0:\n",
    "            yield mx.nd.array(X_split), mx.nd.array(train_y[ti+1-batch_size:ti+1])   \n",
    "            X_split = np.zeros(DATA_SHAPE, dtype='float32')\n",
    "            \n",
    "def example(infile='mnist_train.csv'):\n",
    "    \n",
    "    mbatch = 3\n",
    "    df = pd.read_csv(infile, header=None)\n",
    "    train_y = df[[0]].values.ravel()\n",
    "    print(\"actual: \", train_y[:mbatch*4])\n",
    "        \n",
    "    counter = 0\n",
    "    for batchX, batchY in manual_iterator(infile, batch_size=mbatch, shuffle=False):\n",
    "        print(\"batch: \", batchY.asnumpy().astype('int32'))\n",
    "        counter += 1\n",
    "        if counter == 4:\n",
    "            break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual:  [5 0 4 1 9 2 1 3 1 4 3 5]\n",
      "batch:  [5 0 4]\n",
      "batch:  [1 9 2]\n",
      "batch:  [1 3 1]\n",
      "batch:  [4 3 5]\n"
     ]
    }
   ],
   "source": [
    "example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctx = mx.cpu()\n",
    "cnn = create_lenet()\n",
    "\n",
    "# Manually set-up the training process\n",
    "input_shapes = {'softmax_label': (BATCH_SIZE,),\n",
    "                'data': DATA_SHAPE}\n",
    "\n",
    "# Attach symbol to executor\n",
    "exe = cnn.simple_bind(ctx=mx.cpu(), **input_shapes)\n",
    "   \n",
    "# Create link to data and label (to symbol)\n",
    "arg_arrays = dict(zip(cnn.list_arguments(), exe.arg_arrays))\n",
    "data = exe.arg_dict['data']\n",
    "label = exe.arg_dict['softmax_label']\n",
    "\n",
    "# init weights\n",
    "init = mx.init.Uniform(scale=0.01)\n",
    "for name, arr in arg_arrays.items():\n",
    "    if name not in input_shapes:\n",
    "        init(name, arr)    \n",
    "\n",
    "# Stochastic gradient descent\n",
    "opt = mx.optimizer.SGD(\n",
    "    learning_rate=LR,\n",
    "    momentum=MOM,\n",
    "    wd=WD,\n",
    "    rescale_grad=1.0/BATCH_SIZE)\n",
    "updater = mx.optimizer.get_updater(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 iter: 100 metric(accuracy): 0.1112 dur: 16.0193\n",
      "epoch: 0 iter: 200 metric(accuracy): 0.4231 dur: 25.5562\n",
      "epoch: 0 iter: 300 metric(accuracy): 0.5941 dur: 35.2233\n",
      "epoch: 0 iter: 400 metric(accuracy): 0.6852 dur: 45.1762\n",
      "epoch: 0 iter: 500 metric(accuracy): 0.7413 dur: 56.0308\n",
      "epoch: 0 iter: 600 metric(accuracy): 0.7797 dur: 66.4584\n",
      "epoch: 1 iter: 100 metric(accuracy): 0.8076 dur: 15.9844\n",
      "epoch: 1 iter: 200 metric(accuracy): 0.8290 dur: 25.6956\n",
      "epoch: 1 iter: 300 metric(accuracy): 0.8453 dur: 35.3136\n",
      "epoch: 1 iter: 400 metric(accuracy): 0.8586 dur: 45.0332\n",
      "epoch: 1 iter: 500 metric(accuracy): 0.8696 dur: 54.7026\n",
      "epoch: 1 iter: 600 metric(accuracy): 0.8789 dur: 64.4354\n",
      "epoch: 2 iter: 100 metric(accuracy): 0.8871 dur: 15.7670\n",
      "epoch: 2 iter: 200 metric(accuracy): 0.8942 dur: 25.3493\n",
      "epoch: 2 iter: 300 metric(accuracy): 0.9003 dur: 34.8345\n",
      "epoch: 2 iter: 400 metric(accuracy): 0.9055 dur: 44.3858\n",
      "epoch: 2 iter: 500 metric(accuracy): 0.9102 dur: 54.0566\n",
      "epoch: 2 iter: 600 metric(accuracy): 0.9144 dur: 63.6599\n",
      "epoch: 3 iter: 100 metric(accuracy): 0.9184 dur: 15.7379\n",
      "epoch: 3 iter: 200 metric(accuracy): 0.9221 dur: 25.3709\n",
      "epoch: 3 iter: 300 metric(accuracy): 0.9252 dur: 34.8928\n",
      "epoch: 3 iter: 400 metric(accuracy): 0.9282 dur: 44.4360\n",
      "epoch: 3 iter: 500 metric(accuracy): 0.9309 dur: 54.0196\n",
      "epoch: 3 iter: 600 metric(accuracy): 0.9334 dur: 63.6983\n",
      "epoch: 4 iter: 100 metric(accuracy): 0.9358 dur: 15.9603\n",
      "epoch: 4 iter: 200 metric(accuracy): 0.9380 dur: 25.5808\n",
      "epoch: 4 iter: 300 metric(accuracy): 0.9400 dur: 35.1827\n",
      "epoch: 4 iter: 400 metric(accuracy): 0.9420 dur: 45.0686\n",
      "epoch: 4 iter: 500 metric(accuracy): 0.9437 dur: 54.6140\n",
      "epoch: 4 iter: 600 metric(accuracy): 0.9452 dur: 64.1516\n",
      "epoch: 5 iter: 100 metric(accuracy): 0.9467 dur: 15.9933\n",
      "epoch: 5 iter: 200 metric(accuracy): 0.9483 dur: 25.6827\n",
      "epoch: 5 iter: 300 metric(accuracy): 0.9496 dur: 35.1966\n",
      "epoch: 5 iter: 400 metric(accuracy): 0.9510 dur: 44.8108\n",
      "epoch: 5 iter: 500 metric(accuracy): 0.9522 dur: 54.3777\n",
      "epoch: 5 iter: 600 metric(accuracy): 0.9534 dur: 63.9927\n",
      "epoch: 6 iter: 100 metric(accuracy): 0.9546 dur: 17.0745\n",
      "epoch: 6 iter: 200 metric(accuracy): 0.9557 dur: 26.9278\n",
      "epoch: 6 iter: 300 metric(accuracy): 0.9567 dur: 36.6837\n",
      "epoch: 6 iter: 400 metric(accuracy): 0.9577 dur: 46.2761\n",
      "epoch: 6 iter: 500 metric(accuracy): 0.9587 dur: 55.8306\n",
      "epoch: 6 iter: 600 metric(accuracy): 0.9596 dur: 65.4925\n",
      "epoch: 7 iter: 100 metric(accuracy): 0.9604 dur: 15.7442\n",
      "epoch: 7 iter: 200 metric(accuracy): 0.9613 dur: 25.4264\n",
      "epoch: 7 iter: 300 metric(accuracy): 0.9621 dur: 35.1371\n",
      "epoch: 7 iter: 400 metric(accuracy): 0.9629 dur: 45.0768\n",
      "epoch: 7 iter: 500 metric(accuracy): 0.9636 dur: 54.7542\n",
      "epoch: 7 iter: 600 metric(accuracy): 0.9643 dur: 64.6587\n",
      "epoch: 8 iter: 100 metric(accuracy): 0.9650 dur: 15.5163\n",
      "epoch: 8 iter: 200 metric(accuracy): 0.9657 dur: 25.2957\n",
      "epoch: 8 iter: 300 metric(accuracy): 0.9663 dur: 34.9811\n",
      "epoch: 8 iter: 400 metric(accuracy): 0.9670 dur: 44.5483\n",
      "epoch: 8 iter: 500 metric(accuracy): 0.9676 dur: 54.8188\n",
      "epoch: 8 iter: 600 metric(accuracy): 0.9682 dur: 64.7936\n",
      "epoch: 9 iter: 100 metric(accuracy): 0.9687 dur: 15.8700\n",
      "epoch: 9 iter: 200 metric(accuracy): 0.9693 dur: 25.8014\n",
      "epoch: 9 iter: 300 metric(accuracy): 0.9698 dur: 35.4461\n",
      "epoch: 9 iter: 400 metric(accuracy): 0.9703 dur: 45.0995\n",
      "epoch: 9 iter: 500 metric(accuracy): 0.9708 dur: 54.7773\n",
      "epoch: 9 iter: 600 metric(accuracy): 0.9713 dur: 64.6901\n",
      "Finished training in 646 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n{'softmax_label': (100,), 'data': (100, 1, 28, 28)}\\nepoch: 0 iter: 100 metric(accuracy): 0.1122 dur: 15.8803\\nepoch: 0 iter: 200 metric(accuracy): 0.4161 dur: 25.6026\\nepoch: 0 iter: 300 metric(accuracy): 0.5904 dur: 35.3213\\nepoch: 0 iter: 400 metric(accuracy): 0.6830 dur: 44.9783\\nepoch: 0 iter: 500 metric(accuracy): 0.7395 dur: 54.6165\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "# Evaluation metric:\n",
    "metric = mx.metric.Accuracy()\n",
    "\n",
    "# Train EPOCHS\n",
    "for epoch in range(EPOCHS):\n",
    "    t = 0   \n",
    "    for batchX, batchY in manual_iterator('mnist_train.csv', batch_size=BATCH_SIZE, shuffle=True):\n",
    "        # Copy data to executor input\n",
    "        data[:] = batchX\n",
    "        label[:] = batchY\n",
    "        # forward\n",
    "        exe.forward(is_train=True)\n",
    "        # backward\n",
    "        exe.backward()\n",
    "        # Update\n",
    "        for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
    "            weight, grad = pair\n",
    "            updater(i, grad, weight)\n",
    "        # get metric\n",
    "        metric.update([batchY], exe.outputs)\n",
    "        # log every batch\n",
    "        t += 1\n",
    "        if t % BATCH_SIZE == 0:\n",
    "            toc = time.time()\n",
    "            train_t = toc - tic\n",
    "            metric_m, metric_v = metric.get()\n",
    "            print(\"epoch: %d iter: %d metric(%s): %.4f dur: %.0f\" % (epoch, t, metric_m, metric_v, train_t))\n",
    "\n",
    "print(\"Finished training in %.0f seconds\" % (time.time() - tic))\n",
    "            \n",
    "\"\"\"\n",
    "{'softmax_label': (100,), 'data': (100, 1, 28, 28)}\n",
    "epoch: 0 iter: 100 metric(accuracy): 0.1112 dur: 16.0193\n",
    "epoch: 0 iter: 200 metric(accuracy): 0.4231 dur: 25.5562\n",
    "epoch: 0 iter: 300 metric(accuracy): 0.5941 dur: 35.2233\n",
    "epoch: 0 iter: 400 metric(accuracy): 0.6852 dur: 45.1762\n",
    "epoch: 0 iter: 500 metric(accuracy): 0.7413 dur: 56.0308\n",
    "epoch: 0 iter: 600 metric(accuracy): 0.7797 dur: 66.4584\n",
    "epoch: 1 iter: 100 metric(accuracy): 0.8076 dur: 15.9844#\n",
    "...\n",
    "epoch: 9 iter: 600 metric(accuracy): 0.9713 dur: 64.6901\n",
    "Finished training in 646 seconds\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric(accuracy): 0.9902\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "metric = mx.metric.Accuracy()\n",
    "\n",
    "for batchX, batchY in manual_iterator('mnist_test.csv', batch_size=BATCH_SIZE):\n",
    "    data[:] = batchX\n",
    "    label[:] = batchY\n",
    "    # forward\n",
    "    exe.forward(is_train=False)\n",
    "    # metric for prediction\n",
    "    metric.update([batchY], exe.outputs)\n",
    "\n",
    "metric_m, metric_v = metric.get()\n",
    "print(\"metric(%s): %.4f\" % (metric_m, metric_v))\n",
    "\n",
    "# metric(accuracy): 0.9902"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Method C - Advanced\n",
    "\n",
    "With this approach we create our own iterator which inherits the `DataIter` class, this means\n",
    "we can use it in the normal training approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from mxnet.ndarray import array, NDArray\n",
    "from mxnet.io import DataBatch\n",
    "\n",
    "def init_data(data, default_name):\n",
    "    data = OrderedDict([(default_name, [data][0])])\n",
    "    for k, v in data.items():\n",
    "        if not isinstance(v, NDArray):\n",
    "            data[k] = array(v)\n",
    "    return list(data.items())\n",
    "\n",
    "def csv_to_np(infile):\n",
    "    df = pd.read_csv(infile, header=None)\n",
    "    data, label = df.iloc[:,1:].values, df[[0]].values.ravel()\n",
    "    data = np.array(data, dtype='float32').reshape((-1, 1, 28, 28))\n",
    "    data[:] /= 255.0  # normalise        \n",
    "    return data, label\n",
    "\n",
    "class CustomIter(mx.io.DataIter):\n",
    "    \n",
    "    \"\"\" \n",
    "    Given response on github: You can inherit mx.io.DataIter\n",
    "    to create your own data iterator.\n",
    "    You only need to implement provide_data, provide_label, next() \n",
    "    \n",
    "    This inherits from mx.io.DataIter\"\"\"\n",
    "    \n",
    "    def __init__(self, infile, batch_size=100, shuffle=False):\n",
    "        \n",
    "        super(CustomIter, self).__init__()\n",
    "\n",
    "        # Load all CSV into array\n",
    "        data, label = csv_to_np(infile)\n",
    "            \n",
    "        self.data = init_data(data, 'data')\n",
    "        self.label = init_data(label, 'softmax_label')\n",
    "        \n",
    "        # shuffle\n",
    "        if shuffle:\n",
    "            idx = np.arange(self.data[0][1].shape[0])\n",
    "            np.random.shuffle(idx)  # in-place\n",
    "            self.data = [(k, array(v.asnumpy()[idx], v.context)) for k, v in self.data]\n",
    "            self.label = [(k, array(v.asnumpy()[idx], v.context)) for k, v in self.label]\n",
    "            \n",
    "        # batching\n",
    "        self.data_list = [x[1] for x in self.data] + [x[1] for x in self.label]\n",
    "        self.num_source = len(self.data_list)\n",
    "        self.num_data = self.data_list[0].shape[0]\n",
    "        assert self.num_data >= batch_size, \\\n",
    "            \"batch_size need to be smaller than data size.\"\n",
    "        self.cursor = -batch_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    @property\n",
    "    def provide_data(self):\n",
    "        \"\"\"The name and shape of data provided by this iterator\"\"\"\n",
    "        return [(k, tuple([self.batch_size] + list(v.shape[1:]))) for k, v in self.data]\n",
    "\n",
    "    @property\n",
    "    def provide_label(self):\n",
    "        \"\"\"The name and shape of label provided by this iterator\"\"\"\n",
    "        return [(k, tuple([self.batch_size] + list(v.shape[1:]))) for k, v in self.label]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.cursor = -self.batch_size\n",
    "        \n",
    "    def iter_next(self):\n",
    "        self.cursor += self.batch_size\n",
    "        if self.cursor < self.num_data:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "     \n",
    "    def next(self):\n",
    "        if self.iter_next():\n",
    "            return DataBatch(\n",
    "                data=self._getdata(self.data), \n",
    "                label=self._getdata(self.label),\n",
    "                pad=self.getpad(),\n",
    "                index=None)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "        \n",
    "    def _getdata(self, data_source):\n",
    "        \"\"\"Load data from underlying arrays, internal use only. Any\n",
    "        transformation functions would go here ...\n",
    "        \n",
    "        For example creating one-hot encodings, etc.\"\"\"\n",
    "        \n",
    "        assert(self.cursor < self.num_data), \"DataIter needs reset.\"\n",
    "        \n",
    "        if self.cursor + self.batch_size <= self.num_data:\n",
    "            return [x[1][self.cursor:self.cursor+self.batch_size] for x in data_source]\n",
    "        \n",
    "        else:\n",
    "            pad = self.batch_size - self.num_data + self.cursor\n",
    "            return [concatenate([x[1][self.cursor:], x[1][:pad]]) for x in data_source]\n",
    "    \n",
    "    def getpad(self):\n",
    "        if self.cursor + self.batch_size > self.num_data:\n",
    "            return self.cursor + self.batch_size - self.num_data\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup model\n",
    "model = mx.model.FeedForward(\n",
    "    ctx = ctx,\n",
    "    symbol = cnn, \n",
    "    num_epoch = EPOCHS,  \n",
    "    learning_rate = LR,  \n",
    "    momentum = MOM,   \n",
    "    wd = WD  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Link our custom iterator\n",
    "cust_iter = CustomIter('mnist_train.csv', batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training in 585 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "tic = time.time()\n",
    "\n",
    "model.fit(\n",
    "    X = cust_iter,\n",
    "    eval_metric=['accuracy'],\n",
    "    batch_end_callback=mx.callback.Speedometer(BATCH_SIZE),\n",
    "    epoch_end_callback=mx.callback.do_checkpoint(\"lenet_checkp_\") \n",
    ")\n",
    "\n",
    "print(\"Finished training in %.0f seconds\" % (time.time() - tic))\n",
    "# Finished training in 577 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "test_iter = CustomIter('mnist_test.csv', batch_size=BATCH_SIZE)\n",
    "\n",
    "# most likely will be last element after sorting\n",
    "pred = np.argsort(model.predict(X = test_iter))[:,-1]\n",
    "\n",
    "# accuracy\n",
    "test = pd.read_csv('mnist_test.csv', header=None)\n",
    "test_y = test[[0]].values.ravel()\n",
    "\n",
    "print(sum(pred==test_y)/len(test_y))\n",
    "# 0.991"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
